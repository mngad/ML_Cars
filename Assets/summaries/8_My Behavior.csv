Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.0029999998,-0.07969103,-1.555894714064504,101.36842105263158,-1.537173794015594
20000,1.4235344,0.002999999,-0.23670147,-0.656274488122732,97.29411764705883,-0.704607721637277
30000,1.4246936,0.0029999986,-0.20344782,-1.3531325060694692,107.32530120481928,-1.3229068236988644
40000,1.4226035,0.0029999984,-0.30351108,-0.8195999783277511,97.11,-0.8195998468995094
50000,1.4238007,0.0029999975,-0.45576972,-1.0391999754309653,109.78,-1.068556526887048
60000,1.4217244,0.0029999968,-0.48844713,-1.0152687949919572,99.35483870967742,-0.9854735481111627
