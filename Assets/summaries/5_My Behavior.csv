Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.0029999996,5.9999247,-0.9574550027289661,57.355,-0.9402339068072582
20000,1.4331893,0.0029999986,5.104415,-0.3632229323644238,51.80891719745223,-0.47942163146830896
30000,1.4321706,0.0029999984,2.4935493,-0.656028092495464,55.07865168539326,-0.6503595789747961
40000,1.4278811,0.0029999984,1.6491816,-0.32417127325711514,54.18232044198895,-0.3186408669497427
50000,1.4297158,0.002999997,0.90253246,-0.4099189214439861,53.8054054054054,-0.4027978201788631
60000,1.4354987,0.0029999968,0.46250293,-0.3328379913683273,54.229050279329606,-0.35194475644201206
70000,1.4413191,0.002999996,0.16643009,-0.27380769487385953,54.80769230769231,-0.24953070528513893
80000,1.4442394,0.0029999951,0.011079775,-0.5855932229285333,54.98870056497175,-0.5908379790961077
90000,1.441975,0.002999995,-0.28915724,-0.6752834250704749,55.1283422459893,-0.6992203239667214
100000,1.4308058,0.0029999944,-0.31872034,-0.7956416211454359,56.01156069364162,-0.7529257150632994
110000,1.4174595,0.0029999935,-0.43646142,-0.816094529734512,50.159203980099505,-0.8100255083064644
120000,1.4091911,0.002999993,-0.49900913,-0.6460465141463765,53.43023255813954,-0.6725706493724948
130000,1.4028481,0.0029999926,-0.51400596,-0.5221016067248286,52.0427807486631,-0.5247765792177078
140000,1.3946321,0.0029999916,-0.6014954,-0.5520882380475728,58.241176470588236,-0.5462916585217629
150000,1.3886741,0.0029999914,-0.4839671,-0.696923079491071,54.42307692307692,-0.692933340370655
160000,1.3832488,0.002999991,-0.48489022,-0.525440862700243,52.8494623655914,-0.5388556087319863
170000,1.3809023,0.00299999,-0.45612413,-0.4467065895567397,58.09580838323353,-0.45975148602879257
180000,1.3776865,0.0029999895,-0.5022094,-0.3592228943219756,58.475903614457835,-0.35147303271436403
