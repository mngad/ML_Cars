Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.0029999998,0.2266939,-0.20624997611157597,107.7375,-0.20624984428286552
20000,1.4216077,0.0029999989,0.110386856,-1.8460605803764227,114.01010101010101,-1.8213977083083122
30000,1.4254106,0.0029999984,-0.023581851,-0.36629627210398513,108.95061728395062,-0.4947124387340984
40000,1.4315511,0.0029999982,-0.115729354,-1.0092552949258304,108.44680851063829,-1.0074191990719046
50000,1.4359453,0.0029999972,-0.19874468,-1.0601204555391905,118.06024096385542,-1.061547416661467
60000,1.4329304,0.0029999965,-0.3550264,-1.031204794881394,108.93975903614458,-1.0312046577413398
70000,1.4233267,0.0029999963,-0.3027209,-0.7012370894326991,107.57731958762886,-0.7012369466811111
80000,1.4240577,0.0029999954,-0.37714502,-1.1698850326068786,111.1264367816092,-1.1822091503891834
90000,1.4202559,0.0029999951,-0.4330324,-0.9364834923583728,108.01098901098901,-0.9274998566378718
100000,1.4189419,0.0029999947,-0.4280653,-1.0948999768681824,103.42,-1.0948998430371284
110000,1.4185613,0.0029999935,-0.38118964,-0.8421950979476295,107.6219512195122,-0.8386418057812585
120000,1.4183229,0.0029999933,-0.51748496,-1.0141413912478119,102.41414141414141,-1.0152998366951942
