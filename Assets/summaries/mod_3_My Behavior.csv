Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss
1040000,-0.12858859,1.257122,0.0029999379,-1.3663334932255868,3314.3333333333335,-1.3663334945837657,0.006559,0.024905559
1050000,-0.120899834,1.2569115,0.0029999372,-1.6972729028837585,3639.909090909091,-1.6972729136998004,0.029664736,0.022130646
1060000,-0.10436204,1.2552879,0.0029999367,-1.9265001864987426,3865.625,-1.9265001798048615,0.02802772,0.02137332
1070000,-0.11027391,1.2537912,0.002999936,-2.3065557601059683,4239.777777777777,-2.306555753780736,None,None
1080000,-0.18142566,1.2502501,0.0029999355,None,None,None,0.035071243,0.021566484
1090000,-0.17516047,1.2495518,0.0029999353,None,None,None,0.0020555204,0.02576815
