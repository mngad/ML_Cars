Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
576000,-0.037067723,1.382781,0.033269312,0.026932329,0.00029966087,0.19988695,0.0009988808,585.0,-0.5584999695420265,-0.5584999695420265,1.0
588000,-0.0061333803,1.3812456,0.0041189375,0.019460797,0.0002996536,0.19988453,0.0009988568,776.1428571428571,-0.5777384443924978,-0.5777384443924978,1.0
600000,-0.022355823,1.3813224,0.006908389,0.022840034,0.0002996464,0.19988212,0.0009988331,812.1666666666666,-0.7947571405342647,-0.7947571405342647,1.0
612000,-0.04080112,1.3827852,0.0075561604,0.03438821,0.00029963916,0.19987972,0.0009988092,826.8,-0.5826799750328064,-0.5826799750328064,1.0
624000,-0.027255882,1.3822001,0.0016576727,0.024565984,0.00029963197,0.19987732,0.0009987855,712.5,-0.5712499804794788,-0.5712499804794788,1.0
636000,-0.016761383,1.3802432,0.00078223954,0.017321208,0.00029962475,0.19987491,0.0009987616,1239.0,-0.6238999664783478,-0.6238999664783478,1.0
648000,-0.026146071,1.3793024,0.0007244492,0.021967078,0.0002996175,0.1998725,0.0009987378,1091.0,-1.3591000027954578,-1.3591000027954578,1.0
660000,-0.017383747,1.3804855,0.0019135757,0.024013989,0.00029961026,0.19987008,0.0009987139,1344.0,-0.634399987757206,-0.634399987757206,1.0
672000,-0.01426483,1.3788201,0.0003985107,0.020562543,0.00029960304,0.19986767,0.00099869,1471.0,-0.647099956870079,-0.647099956870079,1.0
684000,-0.014218857,1.3775091,0.00036543,0.02303632,0.0002995958,0.19986525,0.000998666,None,None,None,1.0
696000,-0.016558724,1.3782363,0.00029727546,0.028764097,0.00029958852,0.19986284,0.0009986422,1525.0,-2.1525000259280205,-2.1525000259280205,1.0
708000,-0.012059087,1.3770729,0.0023562314,0.020807125,0.0002995813,0.19986042,0.0009986183,None,None,None,1.0
