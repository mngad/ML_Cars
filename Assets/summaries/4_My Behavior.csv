Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189384,0.0029999996,-0.38344085,0.7388999887858517,234.975,0.7389000637456775
20000,1.4259571,0.002999999,0.46862394,-0.3452745178216776,167.50980392156862,-0.34527448243370246
30000,1.4267944,0.0029999986,0.3460499,0.5151272635144943,193.0,0.5151273209940304
40000,1.4238602,0.0029999984,0.5059191,0.5791454457826066,183.9090909090909,0.5930185764338132
50000,1.4292926,0.0029999975,0.43531767,0.26704443390739874,220.3111111111111,0.25754355266690254
60000,1.4272181,0.0029999968,0.36467075,0.1301999903516844,201.75555555555556,0.13020004729429882
70000,1.4237415,0.002999996,0.27698308,0.17029309515833277,173.63793103448276,0.1943860289297606
80000,1.4239519,0.0029999951,0.12970181,0.4169491441699408,175.52542372881356,0.3899500612169504
90000,1.423133,0.002999995,0.18636952,-0.06112500735616777,154.0625,-0.10692061273942864
100000,1.417729,0.0029999944,0.09121005,0.6072307622669122,146.52307692307693,0.6408182179950404
110000,1.4178324,0.0029999937,0.07396043,0.17544999250094406,157.08333333333334,0.17545002301534016
120000,1.4155812,0.002999993,0.002945365,0.164924044036778,138.45569620253164,0.18144878840599304
130000,1.4141637,0.0029999926,0.012885142,0.16096362846437842,165.4181818181818,0.13801791306052888
140000,1.416716,0.0029999914,-0.119925946,-0.016728578329951102,144.45714285714286,-0.016728512038077625
150000,1.4128247,0.0029999912,-0.026783464,0.24429999260464683,155.18333333333334,0.24430007313688595
